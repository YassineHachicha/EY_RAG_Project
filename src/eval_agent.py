from ml_pipeline import train_and_evaluate

def evaluate_models_for_target(target, models=["xgboost", "randomforest"]):
    """
    √âvalue plusieurs mod√®les pour une cible donn√©e et recommande le meilleur.

    Args:
        target (str): La variable cible (ex: "LoanApproved" ou "RiskClass")
        models (list): Liste des noms de mod√®les √† √©valuer

    Returns:
        dict: Contenant les scores, le meilleur mod√®le et une recommandation
    """
    results = {}

    for model in models:
        print(f"üîç √âvaluation de {model} pour {target}")
        try:
            acc = train_and_evaluate(target, model)
            results[model] = acc
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur avec {model}: {e}")
            results[model] = None

    # Filtrer les mod√®les qui ont bien march√©
    filtered = {k: v for k, v in results.items() if v is not None}

    if not filtered:
        return {
            "target": target,
            "scores": results,
            "best_model": None,
            "recommendation": "Aucun mod√®le n'a pu √™tre √©valu√© avec succ√®s."
        }

    best_model = max(filtered, key=filtered.get)

    return {
        "target": target,
        "scores": results,
        "best_model": best_model,
        "recommendation": f"Le meilleur mod√®le pour {target} est {best_model} avec un score de {filtered[best_model]:.4f}."
    }

# Exemple d'appel manuel (√† retirer si int√©gr√© √† une app)
if __name__ == "__main__":
    print(evaluate_models_for_target("LoanApproved"))
    print(evaluate_models_for_target("RiskClass"))
